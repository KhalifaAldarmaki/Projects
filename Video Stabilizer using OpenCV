import numpy as np
import cv2

# Function to calculate the moving average of a curve using a given radius
def calculate_moving_average(curve, radius):
    # Calculate the window size for the moving average
    window_size = 2 * radius + 1

    # Create a simple uniform kernel for convolution
    kernel = np.ones(window_size) / window_size

    # Pad the curve at both ends to handle edge cases during convolution
    curve_padded = np.pad(curve, (radius, radius), mode='edge')

    # Perform 1D convolution to compute the moving average
    smoothed_curve = np.convolve(curve_padded, kernel, mode='same')

    # Trim the padded regions to obtain the smoothed curve
    smoothed_curve = smoothed_curve[radius:-radius]

    return smoothed_curve

# Function to smooth the trajectory using moving average on each dimension
def smooth_trajectory(trajectory):
    # Create a copy of the original trajectory to store the smoothed values
    smoothed_trajectory = np.copy(trajectory)

    # Iterate over each dimension of the trajectory (columns)
    for i in range(3):
        # Apply the calculate_moving_average function to smooth each dimension
        smoothed_trajectory[:, i] = calculate_moving_average(
            trajectory[:, i],  # Extract the i-th dimension of the trajectory
            radius=SMOOTHING_RADIUS  # Use the specified smoothing radius
        )
    return smoothed_trajectory

# Function to fix the frame border by applying rotation and scaling transformation
def fix_border(frame):
    # Get the shape of the input frame
    frame_shape = frame.shape

    # Create a rotation matrix for fixing the border
    matrix = cv2.getRotationMatrix2D(
        (frame_shape[1] / 2, frame_shape[0] / 2),  # Center of rotation
        0,  # Rotation angle (0 degrees for this case)
        1.04  # Scaling factor to prevent border clipping after rotation
    )

    # Apply the rotation and scaling transformation to fix the border
    frame = cv2.warpAffine(frame, matrix, (frame_shape[1], frame_shape[0]))

    return frame

# Set smoothing radius
SMOOTHING_RADIUS = 50

# Open video capture
cap = cv2.VideoCapture("task1 (1).mp4")

# Get video properties
num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total number of frames in the video
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Width of each frame in pixels
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Height of each frame in pixels
fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second (fps) of the video

# Create VideoWriter for output video
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter("stabilized_output.avi", fourcc, fps, (width, height))

# Read the first frame
_, prev_frame = cap.read()
prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

# Initialize array to store transformations
transforms = np.zeros((num_frames - 1, 3), np.float32)

# Calculate optical flow and estimate affine transformation between frames
for i in range(num_frames - 2):
    # Calculate good features to track in the previous frame
    prev_points = cv2.goodFeaturesToTrack(prev_gray, maxCorners=200, qualityLevel=0.01, minDistance=30, blockSize=3)

    # Read the next frame
    success, curr_frame = cap.read()

    # Break the loop if reading the frame was not successful
    if not success:
        break

    # Convert the current frame to grayscale
    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)

    # Calculate optical flow using Lucas-Kanade method
    curr_points, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_points, None)

    # Ensure the shapes of points are the same
    assert prev_points.shape == curr_points.shape

    # Select only the points that were successfully tracked
    idx = np.where(status == 1)[0]
    prev_points = prev_points[idx]
    curr_points = curr_points[idx]

    # Estimate affine transformation between the tracked points
    matrix, _ = cv2.estimateAffinePartial2D(prev_points, curr_points)

    # Extract translation and rotation information from the transformation matrix
    translation_x = matrix[0, 2]
    translation_y = matrix[1, 2]
    rotation_angle = np.arctan2(matrix[1, 0], matrix[0, 0])

    # Store the calculated transformation parameters in the array
    transforms[i] = [translation_x, translation_y, rotation_angle]

    # Set the current frame as the previous frame for the next iteration
    prev_gray = curr_gray

# Calculate the trajectory by cumulatively summing the transformations
trajectory = np.cumsum(transforms, axis=0)

# Smooth the trajectory using moving average
smoothed_trajectory = smooth_trajectory(trajectory)

# Calculate the difference between the smoothed and original trajectory
difference = smoothed_trajectory - trajectory

# Add the difference back to the original transformations to obtain smooth transformations
transforms_smooth = transforms + difference

# Set video capture position to the beginning
cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

# Process each frame and stabilize the video
for i in range(num_frames - 2):
    # Read the next frame
    success, frame = cap.read()
    if not success:
        break

    # Extract translation and rotation information from smoothed transformations
    translation_x = transforms_smooth[i, 0]
    translation_y = transforms_smooth[i, 1]
    rotation_angle = transforms_smooth[i, 2]

    # Create the transformation matrix for stabilization
    transformation_matrix = np.zeros((2, 3), np.float32)
    transformation_matrix[0, 0] = np.cos(rotation_angle)
    transformation_matrix[0, 1] = -np.sin(rotation_angle)
    transformation_matrix[1, 0] = np.sin(rotation_angle)
    transformation_matrix[1, 1] = np.cos(rotation_angle)
    transformation_matrix[0, 2] = translation_x
    transformation_matrix[1, 2] = translation_y

    # Apply the transformation to stabilize the frame
    frame_stabilized = cv2.warpAffine(frame, transformation_matrix, (width, height))

    # Fix the border of the stabilized frame
    frame_stabilized = fix_border(frame_stabilized)

    # Concatenate the original and stabilized frames side by side
    frame_out = cv2.hconcat([frame, frame_stabilized])

    # Resize the frame if its width exceeds 1920 pixels
    if frame_out.shape[1] > 1920:
        frame_out = cv2.resize(frame_out, (frame_out.shape[1] // 2, frame_out.shape[0] // 2))

    # Display the before and after frames
    cv2.imshow("Before and After", frame_out)
    cv2.waitKey(10)

    # Write the frame to the output video file
    out.write(frame_stabilized)

# Release the video capture and writer, and close any open windows
cap.release()
out.release()
cv2.destroyAllWindows()
